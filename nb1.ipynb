{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67337a0f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "604a96ab",
   "metadata": {},
   "source": [
    "## 1. Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377982b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain langchain-community pypdf sentence-transformers ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from sentence_transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from sentence_transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from sentence_transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from sentence_transformers) (0.33.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from sentence_transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from sentence_transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\amith\\anaconda3\\envs\\torch_env\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Installing collected packages: sentence_transformers\n",
      "Successfully installed sentence_transformers-5.0.0\n"
     ]
    }
   ],
   "source": [
    "# ! pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbaecde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0eeb1f",
   "metadata": {},
   "source": [
    "## --- 1. Data Preparation ---\n",
    "Replace with the path to your technical book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8385007d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split book into 336 chunks.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "book_path = \"C:/Users/amith/Documents/genai_proj1/unix programmers manual.pdf\"\n",
    "loader = PyPDFLoader(book_path)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=300,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Split book into {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d204143",
   "metadata": {},
   "source": [
    "\n",
    "## --- 2. Create Embeddings and Vector Store ---\n",
    "Using a local embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a99855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_37256\\3367226509.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "c:\\Users\\amith\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e9a6f8",
   "metadata": {},
   "source": [
    "### Create a FAISS vector store from the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a99c5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector store (this might take a moment)...\n",
      "Vector store created.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating vector store (this might take a moment)...\")\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "print(\"Vector store created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45134e8c",
   "metadata": {},
   "source": [
    "* You can save and load the vectorstore to avoid re-embedding every time\n",
    "* vectorstore.save_local(\"faiss_index\")\n",
    "* vectorstore = FAISS.load_local(\"faiss_index\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1592dbb",
   "metadata": {},
   "source": [
    "## --- 3. Implement RAG ---\n",
    "* Initialize Ollama LLM (make sure Ollama server is running and model is pulled)\n",
    "* Example: ollama pull gemma:2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be1cebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_37256\\657799462.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"gemma:2b\") # Replace with your chosen Ollama model\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"gemma:2b\") # Replace with your chosen Ollama model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c748cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3}) # Retrieve top 3 relevant chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a6b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your RAG prompt template\n",
    "rag_prompt_template = \"\"\"Use the following context to answer the question at the end.\n",
    "If you don't know the answer, state that you don't know, and do not make up an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "RAG_PROMPT = PromptTemplate(\n",
    "    template=rag_prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e3735e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the RAG chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\", # 'stuff' combines all retrieved documents into one prompt\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True, # Optional: to see which chunks were used\n",
    "    chain_type_kwargs={\"prompt\": RAG_PROMPT}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74067655",
   "metadata": {},
   "source": [
    "## --- 4. Chatbot Interaction (Basic CLI) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cdf9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chatbot initialized! Ask questions about your technical book.\n",
      "Type 'exit' to quit.\n",
      "\n",
      "Chatbot Answer:\n",
      "The context does not provide any information about insurance, double down, or the random number generator, so I cannot answer this question from the context.\n",
      "\n",
      "Chatbot Answer:\n",
      "The context does not provide a list of important commands, so I cannot answer this question from the provided context.\n",
      "\n",
      "Chatbot Answer:\n",
      "The context does not specify what mkdir is, so I cannot answer this question from the context.\n",
      "\n",
      "Chatbot Answer:\n",
      "The context does not provide information about copy commands, so I cannot answer this question from the provided context.\n",
      "\n",
      "Chatbot Answer:\n",
      "Sure, here is the answer to the question:\n",
      "\n",
      "The context does not define what a directory is, so I cannot answer this question from the context.\n",
      "\n",
      "Chatbot Answer:\n",
      "Sure, here's the answer to your question:\n",
      "\n",
      "The context describes a file system format and its structure. It mentions that a file system consists of a super block, a free list of blocks, and a chain of blocks that can be used to store data. It also describes the format of the super block, which contains information about the file, such as its size, number of free blocks, and the type of data it contains.\n",
      "\n",
      "Chatbot Answer:\n",
      "The context does not specify what a directory is, so I cannot answer this question from the context.\n",
      "\n",
      "Chatbot Answer:\n",
      "The context does not provide any information about the answer to the question, so I cannot answer this question from the provided context.\n",
      "\n",
      "Chatbot Answer:\n",
      "According to the context, dup is a function that will allocate another file descriptor to an open file descriptor.\n",
      "\n",
      "Chatbot Answer:\n",
      "The context does not provide any information about the answer to the question, so I cannot answer this question from the context.\n",
      "\n",
      "Chatbot Answer:\n",
      "The context does not provide an answer to the question, so I cannot answer this question from the context.\n",
      "\n",
      "Chatbot Answer:\n",
      "Sure, here is the answer to your question:\n",
      "\n",
      "The context does not provide any information about what the exit command does, or how it is used, so I cannot answer this question from the provided context.\n",
      "\n",
      "Chatbot Answer:\n",
      "The context does not provide any information about the answer to the question, so I cannot answer this question from the context.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nChatbot initialized! Ask questions about your technical book.\")\n",
    "print(\"Type 'exit' to quit.\")\n",
    "\n",
    "while True:\n",
    "    query = input(\"\\nYour question: \")\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    result = qa_chain.invoke({\"query\": query})\n",
    "    print(\"\\nChatbot Answer:\")\n",
    "    print(result[\"result\"])\n",
    "    # Optional: print source documents\n",
    "    # print(\"\\nSource Documents:\")\n",
    "    # for doc in result[\"source_documents\"]:\n",
    "    #     print(f\"- {doc.metadata.get('source', 'Unknown source')}: {doc.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd4655",
   "metadata": {},
   "source": [
    "Chatbot initialized! Ask questions about your technical book.\n",
    "Type 'exit' to quit.\n",
    "\n",
    "Chatbot Answer:\n",
    "The context does not provide any information about what unix is, so I cannot answer this question from the context.\n",
    "\n",
    "Chatbot Answer:\n",
    "The context does not provide any information about important commands to copy files, so I cannot answer this question from the context.\n",
    "\n",
    "Chatbot Answer:\n",
    "Sure, here's the answer to the question:\n",
    "\n",
    "The context does not specify what the ls command is, so I cannot answer this question from the provided context.\n",
    "\n",
    "Chatbot Answer:\n",
    "The context does not specify what cp is, so I cannot answer this question from the context.\n",
    "\n",
    "Chatbot Answer:\n",
    "A directory is a special type of file that contains other files and or directories. A directory is indicated by a bit in the file's i-node entry, and it can have up to 16 entries. The first two words of each entry contain the i-number and filename, respectively, followed by a null-padded string of up to 14 characters. The first two words of each entry are for the directory itself, and the second is for the parent directory.\n",
    "\n",
    "Chatbot Answer:\n",
    "The context does not mention anything about \"hi\", so I cannot answer this question from the context.\n",
    "\n",
    "Chatbot Answer:\n",
    "The context does not provide any information about more, so I cannot answer the question.\n",
    "\n",
    "Chatbot Answer:\n",
    "The context does not specify what mkdir is, so I cannot answer this question from the context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
